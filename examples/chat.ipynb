{"cells":[{"id":"32b169b3","cell_type":"markdown","source":["# Chat Examples"],"metadata":{},"attachments":{}},{"id":"db5819fb","cell_type":"code","execution_count":1,"outputs":[],"source":["from openai import OpenAI\n","\n","# Configure client to use local server\n","client = OpenAI(\n","    base_url=\"http://localhost:10240/v1\",  # Point to local server\n","    api_key=\"not-needed\"  # API key is not required for local server\n",")"],"metadata":{}},{"id":"e3bafa8f","cell_type":"markdown","source":["## v1/chat/completions"],"metadata":{},"attachments":{}},{"id":"d1349a27","cell_type":"markdown","source":["You can directly test using the curl method, as follows:\n","\n","```shell\n","curl http://localhost:10240/v1/chat/completions \\\n","  -H \"Content-Type: application/json\" \\\n","  -d '{\n","    \"model\": \"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","    \"messages\": [\n","      {\n","        \"role\": \"system\",\n","        \"content\": \"You are a helpful assistant.\"\n","      },\n","      {\n","        \"role\": \"user\",\n","        \"content\": \"Hello!\"\n","      }\n","    ]\n","  }'\n","\n","```\n","\n","You can also use OpenAI's Python SDK in the project for access, which can basically be done without feeling. As follows:"],"metadata":{},"attachments":{}},{"id":"280fe5e6-0c7f-4554-93a9-0d30cce21f2b","cell_type":"code","execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"]}],"source":["completion = client.chat.completions.create(\n","  model=\"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello!\"}\n","  ]\n",")\n","\n","print(completion.choices[0].message)"],"metadata":{}},{"id":"539ec72e-a2ae-4abb-a485-6bbd8063bdbd","cell_type":"code","execution_count":66,"outputs":[{"output_type":"execute_result","execution_count":66,"data":{"text/plain":["ChatCompletion(id='chatcmpl-09bf970dc7', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[], refusal=None), message=ChatCompletionMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732527467, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=25, prompt_tokens=3, total_tokens=28, completion_tokens_details=None, prompt_tokens_details=None))"]},"metadata":{}}],"source":["completion"],"metadata":{}},{"id":"4b6e3283","cell_type":"markdown","source":["## logprobs"],"metadata":{},"attachments":{}},{"id":"9c7f76d1-dea2-4b47-a669-2e06757f67e8","cell_type":"code","execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"]}],"source":["completion = client.chat.completions.create(\n","  model=\"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello!\"}\n","  ],\n","  # stream=True,\n","  logprobs=True,\n","  top_logprobs=2, \n",")\n","\n","print(completion.choices[0].message)"],"metadata":{}},{"id":"3c44dd4e-d947-4960-9448-6d8c78d6fa20","cell_type":"code","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":["ChatCompletion(id='chatcmpl-45516e7131', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.140625, top_logprobs=[TopLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.140625), TopLogprob(token='How', bytes=[72, 111, 119], logprob=-2.078125)]), ChatCompletionTokenLogprob(token='!', bytes=[33], logprob=-0.03125, top_logprobs=[TopLogprob(token='!', bytes=[33], logprob=-0.03125), TopLogprob(token='.', bytes=[46], logprob=-3.375)]), ChatCompletionTokenLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-0.71875, top_logprobs=[TopLogprob(token=' It', bytes=[32, 73, 116], logprob=-0.6875), TopLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-0.71875)]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=0.0, top_logprobs=[TopLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=0.0), TopLogprob(token=' may', bytes=[32, 109, 97, 121], logprob=-7.859375)]), ChatCompletionTokenLogprob(token=' I', bytes=[32, 73], logprob=0.0, top_logprobs=[TopLogprob(token=' I', bytes=[32, 73], logprob=0.0), TopLogprob(token=' i', bytes=[32, 105], logprob=-12.484375)]), ChatCompletionTokenLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0625, top_logprobs=[TopLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0625), TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-2.875)]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0, top_logprobs=[TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0), TopLogprob(token=' You', bytes=[32, 89, 111, 117], logprob=-13.640625)]), ChatCompletionTokenLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0, top_logprobs=[TopLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0), TopLogprob(token='?', bytes=[63], logprob=-11.5625)]), ChatCompletionTokenLogprob(token='?', bytes=[63], logprob=0.0, top_logprobs=[TopLogprob(token='?', bytes=[63], logprob=0.0), TopLogprob(token=',', bytes=[44], logprob=-10.921875)]), ChatCompletionTokenLogprob(token='<|eot_id|>', bytes=[60, 124, 101, 111, 116, 95, 105, 100, 124, 62], logprob=0.0, top_logprobs=[TopLogprob(token='<|eot_id|>', bytes=[60, 124, 101, 111, 116, 95, 105, 100, 124, 62], logprob=0.0), TopLogprob(token=' Do', bytes=[32, 68, 111], logprob=-5.9375)])], refusal=None), message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732527948, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=3, total_tokens=13, completion_tokens_details=None, prompt_tokens_details=None))"]},"metadata":{}}],"source":["completion"],"metadata":{}},{"id":"8f969c9f-44c3-4b2a-8257-62bb0fba7a0e","cell_type":"code","execution_count":null,"outputs":[],"source":[""],"metadata":{}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}
