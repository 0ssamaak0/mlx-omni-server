{"cells":[{"id":"32b169b3","cell_type":"markdown","source":["# Chat Examples"],"metadata":{},"attachments":{}},{"id":"db5819fb","cell_type":"code","execution_count":70,"outputs":[],"source":["from openai import OpenAI\n","\n","# Configure client to use local server\n","client = OpenAI(\n","    base_url=\"http://localhost:10240/v1\",  # Point to local server\n","    api_key=\"not-needed\"  # API key is not required for local server\n",")"],"metadata":{}},{"id":"e3bafa8f","cell_type":"markdown","source":["## v1/chat/completions"],"metadata":{},"attachments":{}},{"id":"d1349a27","cell_type":"markdown","source":["You can directly test using the curl method, as follows:\n","\n","```shell\n","curl http://localhost:10240/v1/chat/completions \\\n","  -H \"Content-Type: application/json\" \\\n","  -d '{\n","    \"model\": \"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","    \"messages\": [\n","      {\n","        \"role\": \"system\",\n","        \"content\": \"You are a helpful assistant.\"\n","      },\n","      {\n","        \"role\": \"user\",\n","        \"content\": \"Hello!\"\n","      }\n","    ]\n","  }'\n","\n","```\n","\n","You can also use OpenAI's Python SDK in the project for access, which can basically be done without feeling. As follows:"],"metadata":{},"attachments":{}},{"id":"280fe5e6-0c7f-4554-93a9-0d30cce21f2b","cell_type":"code","execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat for a bit?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"]}],"source":["completion = client.chat.completions.create(\n","  model=\"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello!\"}\n","  ]\n",")\n","\n","print(completion.choices[0].message)"],"metadata":{}},{"id":"539ec72e-a2ae-4abb-a485-6bbd8063bdbd","cell_type":"code","execution_count":72,"outputs":[{"output_type":"execute_result","execution_count":72,"data":{"text/plain":["ChatCompletion(id='chatcmpl-ac6138de1f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat for a bit?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732542634, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=28, prompt_tokens=3, total_tokens=31, completion_tokens_details=None, prompt_tokens_details=None))"]},"metadata":{}}],"source":["completion"],"metadata":{}},{"id":"4e65dbe4-da71-4b7f-a495-a9fbe292d47b","cell_type":"code","execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='Hello!', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\nHello!\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=\" It's\", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n It's\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' nice', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n nice\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n to\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' meet', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n meet\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' you.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n you.\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' Is', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n Is\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' there', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n there\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' something', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n something\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n I\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n can\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n help\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n you\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' with,', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n with,\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' or', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n or\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' would', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n would\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n you\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' like', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n like\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n to\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' chat', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n chat\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' for', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n for\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n a\n****************\nChatCompletionChunk(id='chatcmpl-0870a60d5b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1732542953, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\n"]}],"source":["response = client.chat.completions.create(\n","    model=\"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","    messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello!\"}\n","    ],\n","    temperature=0,\n","    stream=True  # this time, we set stream=True\n",")\n","\n","for chunk in response:\n","    print(chunk)\n","    print(chunk.choices[0].delta.content)\n","    print(\"****************\")"],"metadata":{}},{"id":"4b6e3283","cell_type":"markdown","source":["## logprobs\n","\n","[openai cookbook](https://cookbook.openai.com/examples/using_logprobs#1-using-logprobs-to-assess-confidence-for-classification-tasks)\n"],"metadata":{},"attachments":{}},{"id":"9c7f76d1-dea2-4b47-a669-2e06757f67e8","cell_type":"code","execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"]}],"source":["completion = client.chat.completions.create(\n","  model=\"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello!\"}\n","  ],\n","  # stream=True,\n","  logprobs=True,\n","  top_logprobs=2, \n",")\n","\n","print(completion.choices[0].message)"],"metadata":{}},{"id":"3c44dd4e-d947-4960-9448-6d8c78d6fa20","cell_type":"code","execution_count":74,"outputs":[{"output_type":"execute_result","execution_count":74,"data":{"text/plain":["ChatCompletion(id='chatcmpl-a4a5b3e89c', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.140625, top_logprobs=[TopLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.140625), TopLogprob(token='How', bytes=[72, 111, 119], logprob=-2.078125)]), ChatCompletionTokenLogprob(token='!', bytes=[33], logprob=-0.03125, top_logprobs=[TopLogprob(token='!', bytes=[33], logprob=-0.03125), TopLogprob(token='.', bytes=[46], logprob=-3.375)]), ChatCompletionTokenLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-0.71875, top_logprobs=[TopLogprob(token=' It', bytes=[32, 73, 116], logprob=-0.6875), TopLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-0.71875)]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=0.0, top_logprobs=[TopLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=0.0), TopLogprob(token=' may', bytes=[32, 109, 97, 121], logprob=-7.859375)]), ChatCompletionTokenLogprob(token=' I', bytes=[32, 73], logprob=0.0, top_logprobs=[TopLogprob(token=' I', bytes=[32, 73], logprob=0.0), TopLogprob(token=' i', bytes=[32, 105], logprob=-12.484375)]), ChatCompletionTokenLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0625, top_logprobs=[TopLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0625), TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-2.875)]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0, top_logprobs=[TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0), TopLogprob(token=' You', bytes=[32, 89, 111, 117], logprob=-13.640625)]), ChatCompletionTokenLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0, top_logprobs=[TopLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0), TopLogprob(token='?', bytes=[63], logprob=-11.5625)]), ChatCompletionTokenLogprob(token='?', bytes=[63], logprob=0.0, top_logprobs=[TopLogprob(token='?', bytes=[63], logprob=0.0), TopLogprob(token=',', bytes=[44], logprob=-10.921875)]), ChatCompletionTokenLogprob(token='<|eot_id|>', bytes=[60, 124, 101, 111, 116, 95, 105, 100, 124, 62], logprob=0.0, top_logprobs=[TopLogprob(token='<|eot_id|>', bytes=[60, 124, 101, 111, 116, 95, 105, 100, 124, 62], logprob=0.0), TopLogprob(token=' Do', bytes=[32, 68, 111], logprob=-5.9375)])], refusal=None), message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732542640, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=3, total_tokens=13, completion_tokens_details=None, prompt_tokens_details=None))"]},"metadata":{}}],"source":["completion"],"metadata":{}},{"id":"8f969c9f-44c3-4b2a-8257-62bb0fba7a0e","cell_type":"code","execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token='Hello', logprob=-0.140625, bytes=[72, 101, 108, 108, 111], top_logprobs=[{'token': 'Hello', 'logprob': -0.140625, 'bytes': [72, 101, 108, 108, 111]}, {'token': 'How', 'logprob': -2.078125, 'bytes': [72, 111, 119]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token='!', logprob=-0.03125, bytes=[33], top_logprobs=[{'token': '!', 'logprob': -0.03125, 'bytes': [33]}, {'token': '.', 'logprob': -3.375, 'bytes': [46]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='Hello!', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' It', logprob=-0.6875, bytes=[32, 73, 116], top_logprobs=[{'token': ' It', 'logprob': -0.6875, 'bytes': [32, 73, 116]}, {'token': ' How', 'logprob': -0.71875, 'bytes': [32, 72, 111, 119]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\nHello!\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=\"'s\", logprob=0.0, bytes=[39, 115], top_logprobs=[{'token': \"'s\", 'logprob': 0.0, 'bytes': [39, 115]}, {'token': ' seems', 'logprob': -11.0078125, 'bytes': [32, 115, 101, 101, 109, 115]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=\" It's\", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' nice', logprob=0.0, bytes=[32, 110, 105, 99, 101], top_logprobs=[{'token': ' nice', 'logprob': 0.0, 'bytes': [32, 110, 105, 99, 101]}, {'token': ' great', 'logprob': -6.953125, 'bytes': [32, 103, 114, 101, 97, 116]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n It's\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' nice', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' to', logprob=0.0, bytes=[32, 116, 111], top_logprobs=[{'token': ' to', 'logprob': 0.0, 'bytes': [32, 116, 111]}, {'token': ' of', 'logprob': -15.40625, 'bytes': [32, 111, 102]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n nice\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' meet', logprob=0.0, bytes=[32, 109, 101, 101, 116], top_logprobs=[{'token': ' meet', 'logprob': 0.0, 'bytes': [32, 109, 101, 101, 116]}, {'token': ' help', 'logprob': -5.28125, 'bytes': [32, 104, 101, 108, 112]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n to\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' meet', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' you', logprob=0.0, bytes=[32, 121, 111, 117], top_logprobs=[{'token': ' you', 'logprob': 0.0, 'bytes': [32, 121, 111, 117]}, {'token': ' You', 'logprob': -17.28125, 'bytes': [32, 89, 111, 117]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n meet\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token='.', logprob=0.0, bytes=[46], top_logprobs=[{'token': '.', 'logprob': 0.0, 'bytes': [46]}, {'token': '!', 'logprob': -9.71875, 'bytes': [33]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' you.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' Is', logprob=-0.078125, bytes=[32, 73, 115], top_logprobs=[{'token': ' Is', 'logprob': -0.078125, 'bytes': [32, 73, 115]}, {'token': ' How', 'logprob': -2.703125, 'bytes': [32, 72, 111, 119]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n you.\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' Is', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' there', logprob=0.0, bytes=[32, 116, 104, 101, 114, 101], top_logprobs=[{'token': ' there', 'logprob': 0.0, 'bytes': [32, 116, 104, 101, 114, 101]}, {'token': ' There', 'logprob': -11.546875, 'bytes': [32, 84, 104, 101, 114, 101]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n Is\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' there', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' something', logprob=-0.296875, bytes=[32, 115, 111, 109, 101, 116, 104, 105, 110, 103], top_logprobs=[{'token': ' something', 'logprob': -0.296875, 'bytes': [32, 115, 111, 109, 101, 116, 104, 105, 110, 103]}, {'token': ' anything', 'logprob': -1.359375, 'bytes': [32, 97, 110, 121, 116, 104, 105, 110, 103]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n there\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' something', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' I', logprob=0.0, bytes=[32, 73], top_logprobs=[{'token': ' I', 'logprob': 0.0, 'bytes': [32, 73]}, {'token': ' specific', 'logprob': -6.421875, 'bytes': [32, 115, 112, 101, 99, 105, 102, 105, 99]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n something\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' can', logprob=0.0, bytes=[32, 99, 97, 110], top_logprobs=[{'token': ' can', 'logprob': 0.0, 'bytes': [32, 99, 97, 110]}, {'token': ' Can', 'logprob': -11.46875, 'bytes': [32, 67, 97, 110]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n I\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' help', logprob=-0.015625, bytes=[32, 104, 101, 108, 112], top_logprobs=[{'token': ' help', 'logprob': -0.015625, 'bytes': [32, 104, 101, 108, 112]}, {'token': ' assist', 'logprob': -4.046875, 'bytes': [32, 97, 115, 115, 105, 115, 116]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n can\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' you', logprob=0.0, bytes=[32, 121, 111, 117], top_logprobs=[{'token': ' you', 'logprob': 0.0, 'bytes': [32, 121, 111, 117]}, {'token': 'you', 'logprob': -12.625, 'bytes': [121, 111, 117]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n help\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' with', logprob=0.0, bytes=[32, 119, 105, 116, 104], top_logprobs=[{'token': ' with', 'logprob': 0.0, 'bytes': [32, 119, 105, 116, 104]}, {'token': 'with', 'logprob': -13.28125, 'bytes': [119, 105, 116, 104]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n you\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' with', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' or', logprob=-0.109375, bytes=[32, 111, 114], top_logprobs=[{'token': ' or', 'logprob': -0.109375, 'bytes': [32, 111, 114]}, {'token': ',', 'logprob': -2.4375, 'bytes': [44]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n with\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' or', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' would', logprob=0.0, bytes=[32, 119, 111, 117, 108, 100], top_logprobs=[{'token': ' would', 'logprob': 0.0, 'bytes': [32, 119, 111, 117, 108, 100]}, {'token': ' assist', 'logprob': -8.171875, 'bytes': [32, 97, 115, 115, 105, 115, 116]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n or\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' would', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' you', logprob=0.0, bytes=[32, 121, 111, 117], top_logprobs=[{'token': ' you', 'logprob': 0.0, 'bytes': [32, 121, 111, 117]}, {'token': ' You', 'logprob': -15.515625, 'bytes': [32, 89, 111, 117]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n would\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' like', logprob=0.0, bytes=[32, 108, 105, 107, 101], top_logprobs=[{'token': ' like', 'logprob': 0.0, 'bytes': [32, 108, 105, 107, 101]}, {'token': ' Like', 'logprob': -10.34375, 'bytes': [32, 76, 105, 107, 101]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n you\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' like', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' to', logprob=0.0, bytes=[32, 116, 111], top_logprobs=[{'token': ' to', 'logprob': 0.0, 'bytes': [32, 116, 111]}, {'token': ' some', 'logprob': -6.703125, 'bytes': [32, 115, 111, 109, 101]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n like\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token=' chat', logprob=-0.015625, bytes=[32, 99, 104, 97, 116], top_logprobs=[{'token': ' chat', 'logprob': -0.015625, 'bytes': [32, 99, 104, 97, 116]}, {'token': ' talk', 'logprob': -4.8125, 'bytes': [32, 116, 97, 108, 107]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n to\n****************\nChatCompletionChunk(id='chatcmpl-16b6ac7760', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, refusal=None, token='?', logprob=-0.03125, bytes=[63], top_logprobs=[{'token': '?', 'logprob': -0.03125, 'bytes': [63]}, {'token': ' for', 'logprob': -3.796875, 'bytes': [32, 102, 111, 114]}]))], created=1732545699, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)\n\n****************\n"]}],"source":["response = client.chat.completions.create(\n","    model=\"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","    messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello!\"}\n","    ],\n","    temperature=0,\n","    stream=True,\n","    logprobs=True,\n","    top_logprobs=2, \n",")\n","\n","for chunk in response:\n","    print(chunk)\n","    print(chunk.choices[0].delta.content)\n","    print(\"****************\")"],"metadata":{}},{"id":"e21b5108-1dd2-4d36-ae98-7b066b317b6a","cell_type":"code","execution_count":null,"outputs":[],"source":[""],"metadata":{}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}
