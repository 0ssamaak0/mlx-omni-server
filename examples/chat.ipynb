{"cells":[{"id":"32b169b3","cell_type":"markdown","source":["# Chat Examples"],"metadata":{},"attachments":{}},{"id":"db5819fb","cell_type":"code","execution_count":null,"outputs":[],"source":["from openai import OpenAI\n","\n","# Configure client to use local server\n","client = OpenAI(\n","    base_url=\"http://localhost:8000/v1\",  # Point to local server\n","    api_key=\"not-needed\"  # API key is not required for local server\n",")"],"metadata":{}},{"id":"e3bafa8f","cell_type":"markdown","source":["## v1/chat/completions"],"metadata":{},"attachments":{}},{"id":"d1349a27","cell_type":"markdown","source":["You can directly test using the curl method, as follows:\n","\n","```shell\n","curl http://localhost:8000/v1/chat/completions \\\n","  -H \"Content-Type: application/json\" \\\n","  -d '{\n","    \"model\": \"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","    \"messages\": [\n","      {\n","        \"role\": \"system\",\n","        \"content\": \"You are a helpful assistant.\"\n","      },\n","      {\n","        \"role\": \"user\",\n","        \"content\": \"Hello!\"\n","      }\n","    ]\n","  }'\n","\n","```\n","\n","You can also use OpenAI's Python SDK in the project for access, which can basically be done without feeling. As follows:"],"metadata":{},"attachments":{}},{"id":"280fe5e6-0c7f-4554-93a9-0d30cce21f2b","cell_type":"code","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, name=None)\n"]}],"source":["completion = client.chat.completions.create(\n","  model=\"mlx-community/Llama-3.2-3B-Instruct-4bit\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello!\"}\n","  ]\n",")\n","\n","print(completion.choices[0].message)"],"metadata":{}},{"id":"539ec72e-a2ae-4abb-a485-6bbd8063bdbd","cell_type":"code","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":["ChatCompletion(id='chatcmpl-6be7718d42', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, name=None))], created=1731592559, model='mlx-community/Llama-3.2-3B-Instruct-4bit', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=3, total_tokens=13, completion_tokens_details=None, prompt_tokens_details=None))"]},"metadata":{}}],"source":["completion"],"metadata":{}},{"id":"9c7f76d1-dea2-4b47-a669-2e06757f67e8","cell_type":"code","execution_count":null,"outputs":[],"source":[""],"metadata":{}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}
